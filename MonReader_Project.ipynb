{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Cj2of-uaEr9O0x7r5v3yG6ZPfmSZhdJv",
      "authorship_tag": "ABX9TyOwZE9Ta8nSQvBOZiKxc1M1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedAlYousif-AI/95VhRkOf20buNNcs/blob/main/MonReader_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ddSfoMAShSJ2"
      },
      "outputs": [],
      "source": [
        "#Importing the Essential libraries and their Functions\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import tensorflow.keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Qms5zy9FhXwK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Activation\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.activations import relu, sigmoid\n",
        "from tensorflow.keras.models import Sequential, load_model, save_model\n",
        "from tensorflow.keras.metrics import F1Score"
      ],
      "metadata": {
        "id": "zpwDfPVlhX1s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dataset"
      ],
      "metadata": {
        "id": "0QueBRbolsj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = \"/content/drive/MyDrive/MonReader - Dataset/images/training\"\n",
        "\n",
        "testing_data = \"/content/drive/MyDrive/MonReader - Dataset/images/testing\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R1Rg6M0khX4F",
        "outputId": "02641ed0-b536-4389-a3f7-8a138ce58dad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MonReader - Dataset/images'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Which One of the Three ways below should i use to import the Images correctly?"
      ],
      "metadata": {
        "id": "Kq5_E54C6YZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count(dir, counter=0):\n",
        "    \"returns number of files in dir and subdirs\"\n",
        "    for pack in os.walk(dir):\n",
        "        for f in pack[2]:\n",
        "            counter += 1\n",
        "    return dir + \" : \" + str(counter) + \" files\"\n",
        "\n",
        "\n",
        "\n",
        "print('total images for Training file :', count(training_data))\n",
        "print('total images for Testing file :', count(testing_data))"
      ],
      "metadata": {
        "id": "FXni25-A0qIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing images of the Dataset\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "data = pd.DataFrame()\n",
        "\n",
        "\n",
        "SourcePath = '/content/drive/MyDrive/MonReader - Dataset/images'\n",
        "X = []\n",
        "label = []\n",
        "for folder in os.listdir(SourcePath):\n",
        "    for imageName in  os.listdir(SourcePath+\"\\\\\"+folder):\n",
        "        print(folder+ ' - ' + imageName)\n",
        "        X.append(imageName)\n",
        "        label.append(folder)\n",
        "        #data['imagename'].append(imageName)\n",
        "        #data['label'].append(folder)\n",
        "\n",
        "\n",
        "data = pd.DataFrame(X, label)\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "SqGJZ_Lsa6KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# ... (other imports) ...\n",
        "\n",
        "# Assuming training_data is a directory containing images\n",
        "def load_images_from_directory(directory):\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Adjust file extensions as needed\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            image = Image.open(filepath)  # Use PIL to open the image\n",
        "            image = np.array(image)  # Convert the image to a NumPy array\n",
        "            images.append(image)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load images from your training directory\n",
        "training_data_images = load_images_from_directory(training_data)\n",
        "\n",
        "# Now you can access the shape of your training data\n",
        "print(training_data_images.shape)"
      ],
      "metadata": {
        "id": "CWhIYRg06ljy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing one Image:"
      ],
      "metadata": {
        "id": "ggRKCtJb7xCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(training_data[100])"
      ],
      "metadata": {
        "id": "_XjpjJu91y3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "NExXurL3adIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.shape()"
      ],
      "metadata": {
        "id": "xlWPpoGW8NNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-PVXgQG8VMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.reshape()"
      ],
      "metadata": {
        "id": "0qp9PQDXr7UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size = (224, 224)\n",
        "batch_size= 250"
      ],
      "metadata": {
        "id": "HuMfjbpWhYAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THGviS9BhYDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhTEPkWMoTN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting"
      ],
      "metadata": {
        "id": "OFgVGpmIoVYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_data_x, testing_data_x, training_data_y, testing_data_y = train_test_split(x, y, test_size=0.25, random_state=10)"
      ],
      "metadata": {
        "id": "YvgW75-hoTPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_x.shape"
      ],
      "metadata": {
        "id": "morCkZa2oTSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_y.shape"
      ],
      "metadata": {
        "id": "nBUR0PYioTT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data_x.shape"
      ],
      "metadata": {
        "id": "fvS7P_83rUU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data_y.shape"
      ],
      "metadata": {
        "id": "9kDagINNrUXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_x = training_data_x / 255\n",
        "\n",
        "testing_data_x = testing_data_x / 255"
      ],
      "metadata": {
        "id": "C7eSh0Dm2HgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Model"
      ],
      "metadata": {
        "id": "_Qa-b5VVo1f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) General Neural Network Architecture"
      ],
      "metadata": {
        "id": "zG9GBEusfHWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "\n",
        "         Input(shape=training_data_x.shape, batch_size=batch_size),\n",
        "\n",
        "         Dense(64, activation=\"relu\"),\n",
        "         Dense(128, activation=\"relu\"),\n",
        "         Dense(256, activation=\"relu\"),\n",
        "         Dense(512, activation=\"relu\"),\n",
        "\n",
        "         Dense(2, activation=\"sigmoid\")\n",
        "                  )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KLIBb9Udo7OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Specified CNN Architecture"
      ],
      "metadata": {
        "id": "G6Eauyq5fTOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, Flatten"
      ],
      "metadata": {
        "id": "ouqvoJyafyzg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I will discuss about input_shape in the meeting"
      ],
      "metadata": {
        "id": "wJUe4Fnc3KfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Should it be 224, 224, 1?\n",
        "\n",
        " # Or something else?"
      ],
      "metadata": {
        "id": "7cFDDX2z4iCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "\n",
        "        Conv2D(32, 3, activation=\"relu\", input_shape( , , )),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Conv2D(64, 3, activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Conv2D(128, 3, activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Flatten(),\n",
        "        Dense(2, activation=\"sigmoid\")\n",
        "                  )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FDQ1dUHEfTZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do i need to use Cropping2D after Conv2D?\n",
        "\n",
        "# Since Cropping is needed for the images here\n",
        "\n",
        "# I haven't applied Cropping techniques before using TensorFlow or Keras or by other Deep Learning techniques,\n",
        "# but only with PIL and some simple Image Processing libraries"
      ],
      "metadata": {
        "id": "b6LnnYR848w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['F1Score'])"
      ],
      "metadata": {
        "id": "QsIfJWMBo7Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "ZGmXtA_bplHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EarlyStopping = tensorflow.keras.callbacks.EarlyStopping(\n",
        "    monitor='F1Score',\n",
        "    patience=5,\n",
        "    mode='max',\n",
        "    restore_best_weights=False\n",
        ")"
      ],
      "metadata": {
        "id": "FUuliq6d0IfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_data_x, training_data_y, epochs=60, batch_size=batch_size, verbose=2, callbacks=[EarlyStopping])"
      ],
      "metadata": {
        "id": "si-f2dKZo7g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting using Matplotlib\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y00B0FQLtUb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testing_data_x, testing_data_y)"
      ],
      "metadata": {
        "id": "E-ai0XJTkdI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MonReader(image, model):\n",
        "\n",
        "    image = PIL.imread(image)\n",
        "    image = PIL.cvtColor(image, PIL.COLOR_BGR2RGB)\n",
        "    #image = cv2.resize(image, (224, 224))\n",
        "    image = np.array(image, dtype = 'float32')/255.0\n",
        "    plt.imshow(image)\n",
        "    #image = image.reshape(1, 224,224,3)\n",
        "\n",
        "    label_names = training_data_x.class_indices\n",
        "    dict_class = dict(zip(list(range(len(label_names))), label_names))\n",
        "    clas = model.predict(image).argmax()\n",
        "    name = dict_class[clas]\n",
        "    print('The given image is of \\nClass: {0} \\n  : {1}'.format(clas, name))\n",
        "\n",
        "\n",
        "MonReader(Image path'', model)"
      ],
      "metadata": {
        "id": "or7nQgX73tzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MonReader_Prediction = MonReader(200, model)"
      ],
      "metadata": {
        "id": "gnMqBE2t4LjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or"
      ],
      "metadata": {
        "id": "MN3r_yRf4VkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(testing_data_x)"
      ],
      "metadata": {
        "id": "Y3mkhKP6o7q2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}