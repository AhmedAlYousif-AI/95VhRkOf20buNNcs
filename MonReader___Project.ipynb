{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Cj2of-uaEr9O0x7r5v3yG6ZPfmSZhdJv",
      "authorship_tag": "ABX9TyPavUPVjz0PX8qivpLzurPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedAlYousif-AI/95VhRkOf20buNNcs/blob/main/MonReader___Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ddSfoMAShSJ2"
      },
      "outputs": [],
      "source": [
        "#Importing the Essential libraries and their Functions\n",
        "\n",
        "import os\n",
        "import PIL\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import tensorflow.keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "Qms5zy9FhXwK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Activation\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.activations import relu, sigmoid\n",
        "from tensorflow.keras.models import Sequential, load_model, save_model\n",
        "from tensorflow.keras.metrics import F1Score"
      ],
      "metadata": {
        "id": "zpwDfPVlhX1s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dataset"
      ],
      "metadata": {
        "id": "0QueBRbolsj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = \"/content/drive/MyDrive/MonReader - Dataset/images/training\"\n",
        "\n",
        "testing_data = \"/content/drive/MyDrive/MonReader - Dataset/images/testing\""
      ],
      "metadata": {
        "id": "R1Rg6M0khX4F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Which One of the ways below should i use to import the Images correctly?"
      ],
      "metadata": {
        "id": "Kq5_E54C6YZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count(dir, counter=0):\n",
        "    \"returns number of files in dir and subdirs\"\n",
        "    for pack in os.walk(dir):\n",
        "        for f in pack[2]:\n",
        "            counter += 1\n",
        "    return dir + \" : \" + str(counter) + \" files\"\n",
        "\n",
        "\n",
        "\n",
        "print('total images for Training file :', count(training_data))\n",
        "print('total images for Testing file :', count(testing_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXni25-A0qIl",
        "outputId": "52c72d0d-1234-4eac-e0ae-af8f7d4f6015"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total images for Training file : /content/drive/MyDrive/MonReader - Dataset/images/training : 2392 files\n",
            "total images for Testing file : /content/drive/MyDrive/MonReader - Dataset/images/testing : 606 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing images of the Dataset\n",
        "\n",
        "data = pd.DataFrame()\n",
        "\n",
        "\n",
        "SourcePath = '/content/drive/MyDrive/MonReader - Dataset/images'\n",
        "X = []\n",
        "label = []\n",
        "for folder in os.listdir(SourcePath):\n",
        "    for imageName in  os.listdir(SourcePath+\"\\\\\"+folder):\n",
        "        print(folder+ ' - ' + imageName)\n",
        "        X.append(imageName)\n",
        "        label.append(folder)\n",
        "        #data['imagename'].append(imageName)\n",
        "        #data['label'].append(folder)\n",
        "\n",
        "\n",
        "data = pd.DataFrame(X, label)\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "uOkwIcPf_s69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "img_size = (224, 224)\n",
        "\n",
        "SourcePath = '/content/drive/MyDrive/MonReader - Dataset/images'\n",
        "\n",
        "for folder in os.listdir(SourcePath):\n",
        "    folder_path = os.path.join(SourcePath, folder)\n",
        "    for imageName in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, imageName)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, img_size)\n",
        "            X.append(img)\n",
        "            y.append(folder)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "juWvk-ZOq_Fo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "img_size = (224, 224)\n",
        "\n",
        "SourcePath = '/content/drive/MyDrive/MonReader - Dataset/images'\n",
        "\n",
        "for folder in os.listdir(SourcePath):\n",
        "    folder_path = os.path.join(SourcePath, folder)\n",
        "    for imageName in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, imageName)\n",
        "\n",
        "        print(\"Filename:\", imageName)  # Print the filename\n",
        "        print(\"Filepath:\", img_path)  # Print the filepath\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "           img = cv2.resize(img, img_size)\n",
        "           X.append(img)\n",
        "           y.append(folder)\n",
        "        else:\n",
        "           print(f\"Error: Could not load image at {img_path}\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-keqJkMbNMX",
        "outputId": "2b9051a8-fcad-472b-ea73-e0fa444274c3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filename: flip\n",
            "Filepath: /content/drive/MyDrive/MonReader - Dataset/images/training/flip\n",
            "Error: Could not load image at /content/drive/MyDrive/MonReader - Dataset/images/training/flip\n",
            "Filename: notflip\n",
            "Filepath: /content/drive/MyDrive/MonReader - Dataset/images/training/notflip\n",
            "Error: Could not load image at /content/drive/MyDrive/MonReader - Dataset/images/training/notflip\n",
            "Filename: notflip\n",
            "Filepath: /content/drive/MyDrive/MonReader - Dataset/images/testing/notflip\n",
            "Error: Could not load image at /content/drive/MyDrive/MonReader - Dataset/images/testing/notflip\n",
            "Filename: flip\n",
            "Filepath: /content/drive/MyDrive/MonReader - Dataset/images/testing/flip\n",
            "Error: Could not load image at /content/drive/MyDrive/MonReader - Dataset/images/testing/flip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_size = (224, 224)\n",
        "batch_size= 150\n",
        "\n",
        "classes = ['Flip', 'Not Flip']"
      ],
      "metadata": {
        "id": "HuMfjbpWhYAT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "training_data_generator = ImageDataGenerator()\n",
        "\n",
        "testing_data_generator = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "a0JSmskWfFgl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#flow_from_directory\n",
        "\n",
        "training_data_x = training_data_generator.flow_from_directory(X,\n",
        "                                                              target_size=target_size,\n",
        "                                                              batch_size=batch_size,\n",
        "                                                              classes=classes,\n",
        "                                                              class_mode='binary',\n",
        "                                                              shuffle=True)\n",
        "\n",
        "\n",
        "testing_data_x = testing_data_generator.flow_from_directory(y,\n",
        "                                                            target_size=target_size,\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            classes=classes,\n",
        "                                                            class_mode='binary',\n",
        "                                                            shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "x5rWim2B_n4Y",
        "outputId": "de10a70c-8a58-4b79-bc7c-085412641d6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not ndarray",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-81dc4f4fccf8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#flow_from_directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m training_data_x = training_data_generator.flow_from_directory(X,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                               \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             results.append(\n\u001b[1;32m    468\u001b[0m                 pool.apply_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             results.append(\n\u001b[1;32m    468\u001b[0m                 pool.apply_async(\n",
            "\u001b[0;32m/usr/lib/python3.11/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flow_from_directory\n",
        "\n",
        "training_data_x = training_data_generator.flow_from_directory(SourcePath + '/training',\n",
        "                                                              target_size=target_size,\n",
        "                                                              batch_size=batch_size,\n",
        "                                                              classes=classes,\n",
        "                                                              class_mode='binary',\n",
        "                                                              shuffle=True)\n",
        "\n",
        "\n",
        "testing_data_x = testing_data_generator.flow_from_directory(SourcePath + '/testing',\n",
        "                                                            target_size=target_size,\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            classes=classes,\n",
        "                                                            class_mode='binary',\n",
        "                                                            shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YFWapIuk7Be",
        "outputId": "08c7166d-a23f-4a5b-e304-34ea54467df3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flow_from_directory\n",
        "\n",
        "training_data_x = training_data_generator.flow_from_directory(training_data,\n",
        "                                                              target_size=target_size,\n",
        "                                                              batch_size=batch_size,\n",
        "                                                              classes=classes,\n",
        "                                                              class_mode='binary',\n",
        "                                                              shuffle=True)\n",
        "\n",
        "\n",
        "testing_data_x = testing_data_generator.flow_from_directory(testing_data,\n",
        "                                                            target_size=target_size,\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            classes=classes,\n",
        "                                                            class_mode='binary',\n",
        "                                                            shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYmfNYbOmIsd",
        "outputId": "0b31b80a-ca1d-489c-c79f-89a51dd978ed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing one Image:"
      ],
      "metadata": {
        "id": "ggRKCtJb7xCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(training_data_images[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "_XjpjJu91y3D",
        "outputId": "3907d064-5521-4a6d-b575-5ab544b3f8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 100 is out of bounds for axis 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-91e5263fb665>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "NExXurL3adIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xlWPpoGW8NNC",
        "outputId": "193eac1e-ef98-41fb-8555-5dca79c57403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'training_data_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-be546ff6f640>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_data_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'training_data_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.reshape()"
      ],
      "metadata": {
        "id": "0qp9PQDXr7UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting"
      ],
      "metadata": {
        "id": "OFgVGpmIoVYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_x.shape"
      ],
      "metadata": {
        "id": "morCkZa2oTSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_y.shape"
      ],
      "metadata": {
        "id": "nBUR0PYioTT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data_x.shape"
      ],
      "metadata": {
        "id": "fvS7P_83rUU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data_y.shape"
      ],
      "metadata": {
        "id": "9kDagINNrUXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_x = training_data_x / 255\n",
        "\n",
        "testing_data_x = testing_data_x / 255"
      ],
      "metadata": {
        "id": "C7eSh0Dm2HgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Model"
      ],
      "metadata": {
        "id": "_Qa-b5VVo1f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) General Neural Network Architecture"
      ],
      "metadata": {
        "id": "zG9GBEusfHWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "\n",
        "         Input(shape=training_data_x.shape, batch_size=batch_size),\n",
        "\n",
        "         Dense(64, activation=\"relu\"),\n",
        "         Dense(128, activation=\"relu\"),\n",
        "         Dense(256, activation=\"relu\"),\n",
        "         Dense(512, activation=\"relu\"),\n",
        "\n",
        "         Dense(2, activation=\"sigmoid\")\n",
        "                  )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KLIBb9Udo7OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Specified CNN Architecture"
      ],
      "metadata": {
        "id": "G6Eauyq5fTOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten"
      ],
      "metadata": {
        "id": "ouqvoJyafyzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "\n",
        "        Conv2D(32, 3, activation=\"relu\", input_shape(224, 224, 3)),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Conv2D(64, 3, activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Conv2D(128, 3, activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Flatten(),\n",
        "        Dense(2, activation=\"sigmoid\")\n",
        "                  )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FDQ1dUHEfTZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['F1Score'])"
      ],
      "metadata": {
        "id": "QsIfJWMBo7Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "ZGmXtA_bplHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EarlyStopping = tensorflow.keras.callbacks.EarlyStopping(\n",
        "    monitor='F1Score',\n",
        "    patience=5,\n",
        "    mode='max',\n",
        "    restore_best_weights=False\n",
        ")"
      ],
      "metadata": {
        "id": "FUuliq6d0IfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_data_x, training_data_y, epochs=60, batch_size=batch_size, verbose=2, callbacks=[EarlyStopping])"
      ],
      "metadata": {
        "id": "si-f2dKZo7g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting using Matplotlib\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y00B0FQLtUb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testing_data_x, testing_data_y)"
      ],
      "metadata": {
        "id": "E-ai0XJTkdI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MonReader(image, model):\n",
        "\n",
        "    image = PIL.imread(image)\n",
        "    image = PIL.cvtColor(image, PIL.COLOR_BGR2RGB)\n",
        "    #image = PIL.resize(image, (224, 224))\n",
        "    image = np.array(image, dtype = 'float32')/255.0\n",
        "    plt.imshow(image)\n",
        "    #image = image.reshape(1, 224,224,3)\n",
        "\n",
        "    label_names = training_data_x.class_indices\n",
        "    dict_class = dict(zip(list(range(len(label_names))), label_names))\n",
        "    clas = model.predict(image).argmax()\n",
        "    name = dict_class[clas]\n",
        "    print('The given image is of \\nClass: {0} \\n  : {1}'.format(clas, name))\n",
        "\n",
        "\n",
        "MonReader(Image path'', model)"
      ],
      "metadata": {
        "id": "or7nQgX73tzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MonReader_Prediction = MonReader(200, model)"
      ],
      "metadata": {
        "id": "gnMqBE2t4LjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or"
      ],
      "metadata": {
        "id": "MN3r_yRf4VkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(testing_data_x)"
      ],
      "metadata": {
        "id": "Y3mkhKP6o7q2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}